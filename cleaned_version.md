# Идеи, с которыми стоит ознакомиться

# Краткий обзор спектров ЯМР

## Несколько слов о спектрах ЯМР

Спектроскопия ядерного магнитного резонанса (ЯМР) — это аналитический метод, основанный на взаимодействии атомных ядер (например, $^{1}\mathrm{H}$ и $^{13}\mathrm{C}$) с внешним магнитным полем. Ядра со спином $I = \frac{1}{2}$ поглощают радиочастотную энергию, находясь в этом поле, причём точная резонансная частота зависит от электронной среды ядра. В результате получается спектр, состоящий из отдельных сигналов (пиков), каждый из которых соответствует определённому типу ядер в молекуле.

На практике чаще всего регистрируют как $^{1}\mathrm{H}$-ЯМР (протонный ЯМР), так и $^{13}\mathrm{C}$-ЯМР спектры. В спектре $^{1}\mathrm{H}$ (протонном ЯМР) химические сдвиги обычно наблюдаются в диапазоне примерно 0–13 ppm относительно тетраметилсилана (ТМС). В спектре $^{13}\mathrm{C}$ диапазон химических сдвигов значительно шире ($\approx$ 0–200 ppm), хотя природная распространённость изотопа и чувствительность метода ниже. Поэтому $^{1}\mathrm{H}$ ЯМР особенно полезен для анализа водородного каркаса молекулы, а $^{13}\mathrm{C}$ ЯМР даёт информацию об углеродном скелете.

Каждый сигнал (пик) в спектре характеризуется несколькими параметрами. **Химический сдвиг** ($\delta$, в ppm) — непрерывная величина, показывающая резонансную частоту ядра относительно эталона и отражающая, насколько ядро экранировано или дэкранировано электронной оболочкой. **Мультиплетность** (также называемая картиной расщепления) — категориальная метка, указывающая, как пик расщепляется из-за спин-спинового (J) взаимодействия с соседними ядрами. Обычные обозначения: синглет (s), дублет (d), триплет (t), квартет (q), квинтет (quint), секстет (sext), септет (sept), мультиплет (m).

В $^{1}\mathrm{H}$ ЯМР **интегральная интенсивность** (интеграл) — непрерывная величина, пропорциональная числу эквивалентных протонов, дающих данный сигнал (т.е. площадь под пиком). В $^{13}\mathrm{C}$ ЯМР интеграл обычно не количественный и часто опускается.

Таким образом, для каждой молекулы данные $^{1}\mathrm{H}$ ЯМР можно представить в виде двух непрерывных массивов одинаковой длины — один с химическими сдвигами (ppm), другой с интегральными интенсивностями — и параллельного массива меток мультиплетности. Для $^{13}\mathrm{C}$ ЯМР аналогичная структура данных включает значения химических сдвигов (непрерывные) и метки мультиплетности (категориальные), но без интегральных интенсивностей. Такая организация естественным образом подходит для машинно-обучающих рабочих процессов, в которых спектры векторизуются или кодируются иным способом для предсказательного моделирования.

## Процесс токенизации и извлечения признаков в нашей модели

Вот пример из наших обучающих данных (для $^{1}\mathrm{H}$ спектров). Обратите внимание, что «dd» обозначает двойной дублет (double doublet).

**SMILES молекулы:** COc1ccc(C=O)cc1OC(CDCl3)

**Её спектр в общепринятой нотации:**

¹H ЯМР (400 МГц, CDCl₃, ppm) δ = 9.84 (d, $J$ = 0.9 Гц, 1H), 7.45 (ddd, $J$ = 8.2, 1.8, 0.9 Гц, 1H), 7.40 (s, 1H), 6.97 (d, $J$ = 8.2 Гц, 1H), 3.96 (d, $J$ = 0.8 Гц, 3H), 3.93 (d, $J$ = 0.8 Гц, 3H).

**Наша нотация:**

```json
[
  {"intensity": 3.0, "multiplicity": "s",   "signal": 3.93},
  {"intensity": 3.0, "multiplicity": "s",   "signal": 3.96},
  {"intensity": 1.0, "multiplicity": "d",   "signal": 6.98},
  {"intensity": 1.0, "multiplicity": "d",   "signal": 7.4},
  {"intensity": 1.0, "multiplicity": "dd",  "signal": 7.45},
  {"intensity": 1.0, "multiplicity": "s",   "signal": 9.84}
]
```

Мы используем **обучаемые Фурье фичи** (trainable Fourier features) для извлечения признаков из значений интенсивности и химического сдвига (ppm), следуя подходу, описанному в статье  
[Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains](https://proceedings.neurips.cc/paper_files/paper/2020/file/55053683268957697aa39fba6f231c68-Paper.pdf) (NeurIPS 2020).

Мультиплетность кодируется с помощью фиксированного словаря и преобразуется в векторы через **обучаемые эмбеддинги**.

Все три полученных вектора (для химического сдвига, интенсивности и мультиплетности) затем конкатенируются и проецируются в латентное пространство при помощи **линейного слоя**.

## Пробинг (probing)

Основная идея пробинга выглядит так: давайте возьмём некоторый слой нейронки n и выходы из него. Давайте попробуем предсказывать на основе этих выходов (без использования слоёв с номерами n+1 и более) что-нибудь. Посмотрим, насколько это хорошо получается. Если получается хорошо -- значит, закономерности, на основе которых работает предсказание нейронка уловила на слое n или ранее. Простой пример: взять трансформер-переводчик с русского на английский. Рассмотреть выходы разных слоёв энкодера. Попробовать поучить на них классификатор по частям речь слов. Там, где классификатор начал работать нормально нейронка начала понимать различия между частями речи. 

**ВАЖНЫЙ МОМЕНТ:** классификатор должен быть достаточно тупым (линейный слой, MLP и тд), чтобы не оказалось, что он из весьма сырых представлений выучил что-то, что в них не слишком хорошо выражено.

Очевидно, что пробинг можно заводить как на энкодере (энкодерах, в нашем случае), так и на декодере. Ниже пара идей на эту тему.

* [Статья про пробинг в BERT](https://arxiv.org/pdf/1905.05950) 
* [Самые базовые принципы пробинга](https://aclanthology.org/P18-1198.pdf) 
* [Систематизирующий обзор](https://arxiv.org/pdf/2002.12327)

### Пробинг на энкодере

* Послойный пробинг (layer-by-layer probing)

* Если презультаты линейного пробинга хороши -- можем считать что по таргету, для которого проводили пробинг, пространство на выходе из этого конкретного слоя является линейно-сепарабельным

* Пробинг может быть и нелинейным (например, MLP)

### Пробинг на декодере

* [Пробинг lm heads](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens)

## Something That Can Be Called Geometry

Часто бывает так, что в эмбеддингах значительно изменяются только несколько координат. Это означает, что скрытое пространство является анизотропным.

* Можно проверять пространство на изотропность на различных слоях - идея - строим pca, смотрим как распредлена дисперсия, если условно 90% дисперсии ложится на первые пару-тройку собственных значений, значит пространство анизотропно и осмысленно меняется по паре-тройке направлений всего. 

* Можно смотреть на динамику изотропности/анизотропности. Аналогично предыдущему пункту смотреть посмотреть на зависимость каким-либо образом квантифицированной анизотропности (число собственных значений, покрывающих 90% дисперсии например) в зависимости от слоя.  

* [PCA (Eigenvalue Early Enrichment)](https://practicum.yandex.ru/blog/metod-glavnyh-komponent/)

* [Странная и довольно плохо написанная статья, но она поясняет что происходит](https://arxiv.org/pdf/2510.10655v1)

* Тут бы еще почитать про то, как принято в хемоинформатике сравнивать схожесть молекул - [Вот тут можно посмотреть](https://link.springer.com/article/10.1007/s12293-024-00414-6)

### Сравнение двух моделей

* Существуют различные методы, такие как SVCCA или CKA, которые позволяют сравнивать эмбеддинги из
различных моделей. На мой взгляд, было бы интересно посмотреть, как различаются вложения между моделями,
обученными исключительно на спектрах 13C и на обоих вместе.

* [SVCCA](https://arxiv.org/abs/1706.05806)

* [CKA объяснялка](https://www.emergentmind.com/topics/center-kernel-alignment-cka)
* [CKA статья](https://arxiv.org/pdf/2210.16156)

### Другие методы

* Визуальный анализ

* Также представляется интересным изучить подходы Point Patchiness, Reconstruction Skew и Centroid Distribution. Что касается последнего,
я подозреваю, что центроиды могут коррелировать с особенностями ЯМР, и мы могли бы проверить, насколько они изотропны
(например, с помощью Eigenvalue Early Enrichment).  <добавить папир>

## Анализ attention heads

* Можно посмотреть на классификации голов декодера как в [китайской папире](https://ace.ewapub.com/article/view/13745.pdf), выдумать как классифицировать их автоматически (эвристики или выучить) и понять как классификация скоррелирована с идейностью по токенам

## AE

* Activation maximization <добавить папир>

* Sparce ae над декодером + стиринг.

* [SAE](https://arxiv.org/pdf/2309.08600)

* [объяснялка](https://www.emergentmind.com/topics/sparse-autoencoder-steering)

* [пример](https://arxiv.org/pdf/2502.11356)
